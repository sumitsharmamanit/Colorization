{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cb5652d",
   "metadata": {},
   "source": [
    "# Conditional Colorisation Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c28ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import time\n",
    "from dataloader import ColoringDataset, tensor2img\n",
    "from unet_resblock import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40769b9d",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4429217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dir = \"data/train/\"\n",
    "# training_images = [os.path.join(train_dir, item) for item in os.listdir(train_dir)]\n",
    "# print(f\"Count of image before augmentation: {len(training_images)}\")\n",
    "\n",
    "# for img_name in tqdm.tqdm(training_images):\n",
    "#     imgx = cv2.imread(img_name)\n",
    "#     imgx = cv2.cvtColor(imgx , cv2.COLOR_BGR2RGB)\n",
    "#     flip_imgx = cv2.flip(imgx, 1)\n",
    "#     rot_imgx = cv2.rotate(imgx , cv2.ROTATE_180)\n",
    "#     cv2.imwrite(os.path.join(train_dir, 'rot_image{}.png'.format(training_images.index(img_name))), flip_imgx)\n",
    "#     cv2.imwrite(os.path.join(train_dir, 'rot_image{}.png'.format(training_images.index(img_name))), rot_imgx)\n",
    "\n",
    "# print(f\"Count of image after augmentation: {len(os.listdir(train_dir))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae27d27c",
   "metadata": {},
   "source": [
    "## Define logic for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fcd1a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utility(object):\n",
    "  def __init__(self):\n",
    "    self.reset()\n",
    "  def reset(self):\n",
    "    self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n",
    "  def update(self, val, n=1):\n",
    "    self.val = val\n",
    "    self.sum += val * n\n",
    "    self.count += n\n",
    "    self.avg = self.sum / self.count\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    print('Starting training epoch {}'.format(epoch+1))\n",
    "    model.train()\n",
    "    use_cuda = True\n",
    "    batch_time, data_time, losses = Utility(), Utility(), Utility()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, data in enumerate(tqdm.tqdm(train_loader)):\n",
    "        if use_cuda:\n",
    "            l = data[\"l\"].to('cuda')\n",
    "            ab = data[\"ab\"].to('cuda')\n",
    "            img_gray = data[\"gray\"].to('cuda')\n",
    "            img_cue = data[\"cue\"].to('cuda')\n",
    "\n",
    "        gt_image = torch.cat((l, ab), dim=1)\n",
    "        img_gray_image = torch.cat((l, img_gray,img_cue), dim=1)\n",
    "        # Record time to load data (above)\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # Run forward pass\n",
    "        output_img_gray = model(img_gray_image)\n",
    "        #loss = 1-criterion(output_img_gray, gt_image)\n",
    "        loss = criterion(output_img_gray, gt_image)\n",
    "        losses.update(loss.item(), img_gray_image.size(0))\n",
    "        # Compute gradient and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Record time to do forward and backward passes\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 225 == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                epoch+1, i, len(train_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses))\n",
    "\n",
    "    print(f'training epoch: {epoch+1} completed')\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, save_images, epoch):\n",
    "    model.eval()\n",
    "    use_cuda = True\n",
    "    # Prepare value counters and timers\n",
    "    batch_time, data_time, losses = Utility(), Utility(), Utility()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, data in enumerate(tqdm.tqdm(val_loader)):\n",
    "        if use_cuda:\n",
    "            l = data[\"l\"].to('cuda')\n",
    "            ab = data[\"ab\"].to('cuda')\n",
    "            img_gray = data[\"gray\"].to('cuda')\n",
    "            img_cue = data[\"cue\"].to('cuda')\n",
    "\n",
    "        gt_image = torch.cat((l, ab), dim=1)\n",
    "        img_gray_image = torch.cat((l, img_gray, img_cue), dim=1)\n",
    "        data_time.update(time.time() - end)\n",
    "        output_img_gray = model(img_gray_image)\n",
    "\n",
    "        #loss = 1-criterion(output_img_gray, gt_image)\n",
    "        loss = criterion(output_img_gray, gt_image)\n",
    "        losses.update(loss.item(), img_gray_image.size(0))\n",
    "\n",
    "        # Record time to do forward passes and save images\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Validate: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                i, len(val_loader), batch_time=batch_time, loss=losses))\n",
    "        out_img_gray_np = tensor2img(output_img_gray)\n",
    "        out_img_gray_bgr = cv2.cvtColor(out_img_gray_np, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "        cv2.imwrite(\"outputs/outputs/output_\"+str(i)+\".png\", out_img_gray_bgr)\n",
    "\n",
    "    print('Validation Completed.')\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a926f2ff",
   "metadata": {},
   "source": [
    "### Prepare Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c69f08e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "use_cuda = True\n",
    "\n",
    "train_dataset = ColoringDataset(data_dir, 128)\n",
    "train_dataset.set_mode(\"training\")\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "test_dataset = ColoringDataset(data_dir, 128)\n",
    "test_dataset.set_mode(\"validation\")\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4166674",
   "metadata": {},
   "source": [
    "## Load and set Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d28b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResAttdU_Net()\n",
    "# print(model)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=25e-5, weight_decay=0.0)\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21ed9f2",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a1bb8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2251 [00:00<11:06,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/2251]\tTime 0.559 (0.559)\tData 0.175 (0.175)\tLoss 0.7398 (0.7398)\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 91/2251 [00:10<04:06,  8.77it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1c786493a176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-f810f7e249ec>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Record time to do forward and backward passes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                    )\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Make folders and set parameters\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "save_images = True\n",
    "best_losses = 1e10\n",
    "epochs = 150\n",
    "\n",
    "# Train model\n",
    "for epoch in range(epochs):\n",
    "    train(train_dataloader, model, criterion, optimizer, epoch)\n",
    "    with torch.no_grad():\n",
    "        losses = validate(test_dataloader, model, criterion, save_images, epoch)\n",
    "    # Save checkpoint\n",
    "    if losses < best_losses:\n",
    "        best_losses = losses\n",
    "        torch.save(model.state_dict(), 'checkpoints/model-epoch-{}-losses-{:.3f}.pth'.format(epoch + 1, losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9493a6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
